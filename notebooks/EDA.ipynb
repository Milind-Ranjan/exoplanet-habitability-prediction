{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Exoplanet Habitability Prediction - Exploratory Data Analysis\n",
        "\n",
        "This notebook provides a comprehensive analysis of the NASA exoplanet dataset to understand the characteristics of known exoplanets and identify patterns that could indicate habitability potential.\n",
        "\n",
        "## Table of Contents\n",
        "1. [Data Loading and Overview](#data-loading)\n",
        "2. [Data Cleaning](#data-cleaning)\n",
        "3. [Feature Analysis](#feature-analysis)\n",
        "4. [Habitability Criteria](#habitability-criteria)\n",
        "5. [Visualizations](#visualizations)\n",
        "6. [Key Insights](#insights)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style for better visualizations\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Display settings\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', 100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv('../data/exoplanet.csv', comment='#')\n",
        "\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"Number of exoplanets: {df.shape[0]:,}\")\n",
        "print(f\"Number of features: {df.shape[1]:,}\")\n",
        "\n",
        "# Display basic information\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"DATASET OVERVIEW\")\n",
        "print(\"=\"*50)\n",
        "df.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Examine the first few rows\n",
        "print(\"First 5 rows of the dataset:\")\n",
        "print(\"-\" * 50)\n",
        "display(df.head())\n",
        "\n",
        "print(\"\\nColumn names:\")\n",
        "print(\"-\" * 20)\n",
        "for i, col in enumerate(df.columns):\n",
        "    print(f\"{i+1:2d}. {col}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Key columns for habitability analysis\n",
        "key_columns = [\n",
        "    'pl_name', 'hostname', 'pl_rade', 'pl_radj', 'pl_bmasse', 'pl_bmassj',\n",
        "    'pl_orbper', 'pl_orbsmax', 'pl_eqt', 'st_teff', 'st_rad', 'st_mass',\n",
        "    'discoverymethod', 'disc_year', 'sy_dist'\n",
        "]\n",
        "\n",
        "# Create a subset with key columns\n",
        "df_key = df[key_columns].copy()\n",
        "\n",
        "print(\"Key columns for analysis:\")\n",
        "print(\"-\" * 30)\n",
        "for col in key_columns:\n",
        "    print(f\"• {col}\")\n",
        "\n",
        "print(f\"\\nKey dataset shape: {df_key.shape}\")\n",
        "display(df_key.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Missing data analysis\n",
        "print(\"MISSING DATA ANALYSIS\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "missing_data = df_key.isnull().sum()\n",
        "missing_percent = (missing_data / len(df_key)) * 100\n",
        "\n",
        "missing_df = pd.DataFrame({\n",
        "    'Column': missing_data.index,\n",
        "    'Missing_Count': missing_data.values,\n",
        "    'Missing_Percentage': missing_percent.values\n",
        "}).sort_values('Missing_Percentage', ascending=False)\n",
        "\n",
        "print(missing_df.to_string(index=False))\n",
        "\n",
        "# Visualize missing data\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "missing_df.plot(x='Column', y='Missing_Percentage', kind='bar', ax=plt.gca())\n",
        "plt.title('Missing Data Percentage by Column')\n",
        "plt.xticks(rotation=45)\n",
        "plt.ylabel('Missing Percentage (%)')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.heatmap(df_key.isnull(), cbar=True, yticklabels=False, cmap='viridis')\n",
        "plt.title('Missing Data Heatmap')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Statistical summary of key numerical features\n",
        "numerical_cols = ['pl_rade', 'pl_radj', 'pl_bmasse', 'pl_bmassj', 'pl_orbper', \n",
        "                 'pl_orbsmax', 'pl_eqt', 'st_teff', 'st_rad', 'st_mass']\n",
        "\n",
        "print(\"STATISTICAL SUMMARY\")\n",
        "print(\"=\" * 50)\n",
        "display(df_key[numerical_cols].describe())\n",
        "\n",
        "# Correlation analysis\n",
        "plt.figure(figsize=(12, 8))\n",
        "correlation_matrix = df_key[numerical_cols].corr()\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,\n",
        "            square=True, linewidths=0.5)\n",
        "plt.title('Correlation Matrix of Exoplanet Features')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nKey Correlations:\")\n",
        "print(\"-\" * 20)\n",
        "# Find strong correlations (|r| > 0.5)\n",
        "for i in range(len(correlation_matrix.columns)):\n",
        "    for j in range(i+1, len(correlation_matrix.columns)):\n",
        "        corr_val = correlation_matrix.iloc[i, j]\n",
        "        if abs(corr_val) > 0.5:\n",
        "            print(f\"{correlation_matrix.columns[i]} ↔ {correlation_matrix.columns[j]}: {corr_val:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Discovery trends analysis\n",
        "print(\"DISCOVERY TRENDS ANALYSIS\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# Discovery by year\n",
        "discovery_by_year = df_key.groupby('disc_year').size()\n",
        "print(f\"Discovery years range: {discovery_by_year.index.min():.0f} - {discovery_by_year.index.max():.0f}\")\n",
        "print(f\"Peak discovery year: {discovery_by_year.idxmax():.0f} ({discovery_by_year.max()} discoveries)\")\n",
        "\n",
        "# Discovery methods\n",
        "discovery_methods = df_key['discoverymethod'].value_counts()\n",
        "print(f\"\\nTop 5 Discovery Methods:\")\n",
        "print(\"-\" * 25)\n",
        "for method, count in discovery_methods.head().items():\n",
        "    percentage = (count / len(df_key)) * 100\n",
        "    print(f\"{method}: {count} ({percentage:.1f}%)\")\n",
        "\n",
        "# Visualizations\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "# Discovery timeline\n",
        "axes[0,0].plot(discovery_by_year.index, discovery_by_year.values, marker='o')\n",
        "axes[0,0].set_title('Exoplanet Discoveries Over Time')\n",
        "axes[0,0].set_xlabel('Discovery Year')\n",
        "axes[0,0].set_ylabel('Number of Discoveries')\n",
        "axes[0,0].grid(True, alpha=0.3)\n",
        "\n",
        "# Discovery methods (top 10)\n",
        "top_methods = discovery_methods.head(10)\n",
        "axes[0,1].barh(range(len(top_methods)), top_methods.values)\n",
        "axes[0,1].set_yticks(range(len(top_methods)))\n",
        "axes[0,1].set_yticklabels(top_methods.index, fontsize=8)\n",
        "axes[0,1].set_title('Top 10 Discovery Methods')\n",
        "axes[0,1].set_xlabel('Number of Discoveries')\n",
        "\n",
        "# Planet radius distribution\n",
        "axes[1,0].hist(df_key['pl_rade'].dropna(), bins=50, alpha=0.7, edgecolor='black')\n",
        "axes[1,0].set_title('Distribution of Planet Radius')\n",
        "axes[1,0].set_xlabel('Planet Radius (Earth radii)')\n",
        "axes[1,0].set_ylabel('Frequency')\n",
        "axes[1,0].set_xlim(0, 10)\n",
        "\n",
        "# Stellar temperature distribution\n",
        "axes[1,1].hist(df_key['st_teff'].dropna(), bins=50, alpha=0.7, edgecolor='black', color='orange')\n",
        "axes[1,1].set_title('Distribution of Stellar Temperature')\n",
        "axes[1,1].set_xlabel('Stellar Temperature (K)')\n",
        "axes[1,1].set_ylabel('Frequency')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
